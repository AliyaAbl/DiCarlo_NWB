{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used after the inventory is created. It is creating config files for each recording and creating nwb files for spike times and psth (if avail). Then the nwb files are validated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "import os, yaml, glob, json, sys, shutil, logging, h5py, pytz, scipy.io\n",
    "import pandas as pd\n",
    "from nwbwidgets import nwb2widget\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "from pynwb.file import Subject\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(os.path.dirname(cwd))\n",
    "\n",
    "from utils.nwb_helper import  create_nwb, calc_psth\n",
    "from utils.config_helper import create_yaml\n",
    "\n",
    "df = pd.read_excel( os.path.dirname(cwd)+'/pico_inventory.xlsx')\n",
    "SubjectName = 'pico'\n",
    "storage_dir = '/braintree/home/aliya277/inventory_new'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create config files for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Config File for exp_bold5000.sub_solo.20190220_143521.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190220_160047.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190221_095435.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190222_120151.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190225_111537.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190226_094812.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190227_122653.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190304_120611.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190305_112242.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190306_122612.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190307_132706.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190308_120834.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190311_113347.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190312_130545.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190317_115104.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190318_114005.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190319_115956.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190322_114704.proc\n",
      "Creating Config File for exp_bold5000.sub_solo.20190326_100317.proc\n"
     ]
    }
   ],
   "source": [
    "############### Create Custom Config Files for Each Recording #################\n",
    "###############################################################################\n",
    "\n",
    "# If you have new data from pico, which is not in the original excel file 'pico_inventory.xlsx', then set this to False.\n",
    "data_from_excel_file  = True \n",
    "\n",
    "# Adjust these paths if needed.\n",
    "array_meta_path       = '/braintree/data2/active/users/sgouldin/array-metadata'\n",
    "# array_meta_path       = '/braintree/home/aliya277/sachis_data/' # only for sachi's data\n",
    "\n",
    "\n",
    "#experiment_file_paths = glob.glob(os.path.join(storage_dir, '[norm]*', '*', '*'))\n",
    "experiment_file_paths = glob.glob(os.path.join(storage_dir, '[exp]*', '*', '*'))\n",
    "\n",
    "for experiment_path in experiment_file_paths: \n",
    "    if os.path.isdir(experiment_path):\n",
    "        for experiment_session in os.listdir(experiment_path):\n",
    "            if experiment_session.endswith('proc'): \n",
    "                experiment_name_full = experiment_session.split('.')[0]\n",
    "                subject_name_full    = experiment_session.split('.')[1]\n",
    "                date_time_full       = experiment_session.split('.')[2]\n",
    "\n",
    "                # if subject_name_full != 'sub_solo': continue # remove if not solo\n",
    "\n",
    "                experiment_name = '_'.join(experiment_name_full.split('_')[1:])\n",
    "\n",
    "                if experiment_name == 'HVM':\n",
    "                    experiment_name = 'normalizers-HVM'\n",
    "                elif experiment_name == 'FOSS':\n",
    "                    experiment_name = 'normalizers'\n",
    "\n",
    "                subject         = subject_name_full.split('_')[1]\n",
    "                date            = date_time_full.split('_')[0]\n",
    "                time            = date_time_full.split('_')[1]\n",
    "\n",
    "                if not os.path.isfile(os.path.join(experiment_path,experiment_session,f\"config_nwb.yaml\")):\n",
    "            \n",
    "                    print(f'Creating Config File for {experiment_session}')\n",
    "\n",
    "                    if subject == 'pico' and data_from_excel_file:\n",
    "                        try: num_files = len(os.listdir(os.path.join(experiment_path,experiment_session, 'SpikeTimes')))\n",
    "                        except: \n",
    "                            path = os.listdir(os.path.join(experiment_path,experiment_session, 'psth'))[0]\n",
    "                            mat = sio.loadmat(os.path.join(experiment_path,experiment_session, 'psth', path))\n",
    "                            num_files = mat['psth'].shape[-1]\n",
    "\n",
    "                        if num_files == 192: \n",
    "                            array_metadata = os.path.join(array_meta_path, '021023_pico_mapping_noCIT_adapter_version.json')\n",
    "                            adapter_info_avail = True\n",
    "                        elif num_files == 288: \n",
    "                            array_metadata = os.path.join(array_meta_path,'pico_firstmapping_Lhem_2023.json')\n",
    "                            adapter_info_avail = False\n",
    "                        \n",
    "                        indices = df.index[df['ImageSet'] == experiment_name]\n",
    "                        DataFrame = df.loc[indices]\n",
    "                        create_yaml(storage_dir, experiment_name, subject, date, time, array_metadata, df = DataFrame, adapter_info_avail=adapter_info_avail)\n",
    "                    \n",
    "                    if subject == 'solo':\n",
    "                        array_metadata = os.path.join(array_meta_path, 'solo_mapping.json')\n",
    "                        create_yaml(storage_dir, experiment_name, subject, date, time, array_metadata, df = None, adapter_info_avail=False)\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always check the config files for your recording, especially if it is another animal. The config file is adjusted for pico, but you can easily change the data once the file is created of in the config_helper file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create nwb files for each recording and/or update nwb files with newly created psth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NWB File for exp_bold5000.sub_solo.20190220_160047.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190220_160047.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190221_095435.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190221_095435.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190222_120151.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190222_120151.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190225_111537.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190225_111537.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190226_094812.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190226_094812.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190227_122653.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190227_122653.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190304_120611.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190304_120611.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190305_112242.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190305_112242.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190306_122612.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190306_122612.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190307_132706.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190307_132706.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190308_120834.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190308_120834.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190311_113347.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190311_113347.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190312_130545.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190312_130545.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190317_115104.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190317_115104.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190318_114005.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190318_114005.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190319_115956.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190319_115956.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190322_114704.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190322_114704.proc already has psth\n",
      "Creating NWB File for exp_bold5000.sub_solo.20190326_100317.proc\n",
      "Saving NWB File.\n",
      "File saved.\n",
      "File exp_bold5000.sub_solo.20190326_100317.proc already has psth\n"
     ]
    }
   ],
   "source": [
    "############### Iterate through every File and Create NWB #####################\n",
    "###############################################################################\n",
    "\n",
    "experiment_file_paths = glob.glob(os.path.join(storage_dir, '[exp]*', '*', '*'))\n",
    "#experiment_file_paths = glob.glob(os.path.join(storage_dir, '[norm]*', '*', '*')) \n",
    "for experiment_path in experiment_file_paths: \n",
    "    if os.path.isdir(experiment_path):\n",
    "        for experiment_session in os.listdir(experiment_path):\n",
    "            if experiment_session.endswith('proc'):    \n",
    "\n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                # Define names and direcotries.\n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                experiment_name_full = experiment_session.split('.')[0]\n",
    "                subject_name_full    = experiment_session.split('.')[1]\n",
    "                date_time_full       = experiment_session.split('.')[2]\n",
    "\n",
    "                experiment_name = '_'.join(experiment_name_full.split('_')[1:])\n",
    "                subject         = subject_name_full.split('_')[1]\n",
    "                date            = date_time_full.split('_')[0]\n",
    "                time            = date_time_full.split('_')[1]\n",
    "\n",
    "                if subject == 'pico': continue\n",
    "                    \n",
    "                if experiment_name == 'HVM':\n",
    "                    directory = f\"norm_HVM.sub_{subject}.{date}_{time}.proc\"\n",
    "                elif experiment_name == 'FOSS':\n",
    "                    directory = f\"norm_FOSS.sub_{subject}.{date}_{time}.proc\"\n",
    "                else:\n",
    "                    directory = f\"exp_{experiment_name}.sub_{subject}.{date}_{time}.proc\"\n",
    "\n",
    "                imagesetdir = os.path.join(storage_dir, \".\".join(directory.split(\".\")[0:1]))\n",
    "                subjectdir  = os.path.join(storage_dir, imagesetdir, \".\".join(directory.split(\".\")[0:2]))\n",
    "                subjectdir_date  = os.path.join(subjectdir, \".\".join(directory.split(\".\")[0:2])+'.'+date)\n",
    "\n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                # Create proc NWB files for each recording session.\n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                if os.path.isfile(os.path.join(subjectdir_date,directory, f\"{directory}.nwb\")): # TODO ADD NOT\n",
    "                    print(f'Creating NWB File for {directory}')\n",
    "                    with open(os.path.join(subjectdir_date,directory,f\"config_nwb.yaml\") , \"r\") as f:\n",
    "                        config = yaml.load(f, Loader = yaml.FullLoader)\n",
    "                    \n",
    "                    nwbfile = create_nwb(config, os.path.join(subjectdir_date,directory))\n",
    "                    \n",
    "                    print('Saving NWB File.')\n",
    "                    io = NWBHDF5IO(os.path.join(os.path.join(subjectdir_date,directory), f\"{directory}.nwb\"), \"w\") \n",
    "                    io.write(nwbfile)\n",
    "\n",
    "                    # display(nwbfile)\n",
    "                    try:\n",
    "                        psth = nwbfile.scratch['psth'][:]\n",
    "                        meta = nwbfile.scratch['psth meta'][:]\n",
    "                        print(psth.shape, meta)\n",
    "                    except:\n",
    "                        print('No PSTH in this file.')\n",
    "                            \n",
    "                    io.close()\n",
    "                    print(f\"File saved.\")\n",
    "                \n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                # If proc NWB files lready exist, add PSTH and PSTH meta if not already done.\n",
    "                #-----------------------------------------------------------------------------------------\n",
    "                if os.path.isfile(os.path.join(subjectdir_date,directory, f\"{directory}.nwb\")) and os.path.isdir(os.path.join(subjectdir_date,directory,'psth')):\n",
    "                    try: \n",
    "                        io = NWBHDF5IO(os.path.join(os.path.join(subjectdir_date,directory), f\"{directory}.nwb\"), \"a\")\n",
    "                        exp_nwbfile = io.read()\n",
    "\n",
    "                        try: \n",
    "                            exp_nwbfile.scratch['psth']\n",
    "                            print(f'File {directory} already has psth')\n",
    "                        except:\n",
    "                            print(f\"Adding psth to file {directory}\")\n",
    "                            path = os.path.join(os.path.join(subjectdir_date,directory))\n",
    "                            psthpath = path+'/psth/'+os.listdir(path+'/psth')[0]\n",
    "                            psth = scipy.io.loadmat(psthpath)\n",
    "                            data = psth['psth']\n",
    "                            start_time_ms, stop_time_ms, tb_ms = psth['meta'][0][0]\n",
    "                            meta = [start_time_ms.flatten()[0], stop_time_ms.flatten()[0], tb_ms.flatten()[0]]\n",
    "\n",
    "                            exp_nwbfile.add_scratch(\n",
    "                                data,\n",
    "                                name=\"psth\",\n",
    "                                description=\"psth [stimuli x reps x timebins x channels]\",\n",
    "                                )\n",
    "                            \n",
    "                            exp_nwbfile.add_scratch(\n",
    "                                    meta,\n",
    "                                    name=\"psth meta\",\n",
    "                                    description=\"start_time_ms, stop_time_ms, tb_ms\",\n",
    "                                    )\n",
    "                            io.write(exp_nwbfile)                        \n",
    "                        io.close()\n",
    "\n",
    "                    except: print(f\"Can't open file {directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Validate the nwb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Check if All Files are Written and can be Opened ##############\n",
    "###############################################################################\n",
    "\n",
    "i = 0\n",
    "for index, DataFrame in df.iterrows():\n",
    "        \n",
    "    if DataFrame['Has SpikeTime'] == 1:\n",
    "        print(DataFrame['ImageSet'])\n",
    "        \n",
    "        date = f\"20{DataFrame['date']}\"\n",
    "        if len(str(DataFrame['time'])) != 6: time = f\"0{DataFrame['time']}\"\n",
    "        else: time = str(DataFrame['time'])\n",
    "        \n",
    "        if DataFrame['ImageSet'] == 'normalizers':\n",
    "            directory = f'norm_FOSS.sub_pico.{date}_{time}.proc'\n",
    "        elif DataFrame['ImageSet'] == 'normalizers-HVM':\n",
    "            directory = f'norm_HVM.sub_pico.{date}_{time}.proc'\n",
    "        else: \n",
    "            directory = f\"exp_{DataFrame['ImageSet']}.sub_pico.{date}_{time}.proc\"\n",
    "\n",
    "        \n",
    "        imagesetdir = os.path.join(storage_dir, \".\".join(directory.split(\".\")[0:1]))\n",
    "        subjectdir  = os.path.join(storage_dir, imagesetdir, \".\".join(directory.split(\".\")[0:2]))\n",
    "        subjectdir_date  = os.path.join(subjectdir, \".\".join(directory.split(\".\")[0:2])+'.'+date)\n",
    "\n",
    "        try:\n",
    "                io = NWBHDF5IO(os.path.join(os.path.join(subjectdir_date,directory), f\"{directory}.nwb\"), \"r\") \n",
    "                nwbfile = io.read()\n",
    "                io.close()\n",
    "        except: print(f'{i}: This File can not be opened: {directory}')\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Validate All Files Using pwnyb, nwbinspectors #################\n",
    "###############################################################################\n",
    "\n",
    "from pynwb import validate\n",
    "from nwbinspector import inspect_nwbfile\n",
    "from dandi.validate import validate as dandival\n",
    "all_nwb_paths = glob.glob(os.path.join(storage_dir, '*', '*','*','*', '*[nwb]'))\n",
    "\n",
    "for i in range(0,num_files):\n",
    "    j = i\n",
    "    if i + 1 < num_files: i += 1\n",
    "    else: i = num_files\n",
    "    print(f\"Checking Files for {j}:{i}\")\n",
    "    pynwb_validation = validate(paths = all_nwb_paths[j:i])\n",
    "    print(pynwb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbinspector_validation = []\n",
    "for path in all_nwb_paths:\n",
    "    results = list(inspect_nwbfile(nwbfile_path=path))\n",
    "    print(results)\n",
    "    nwbinspector_validation.append(results)\n",
    "nwbinspector_validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
