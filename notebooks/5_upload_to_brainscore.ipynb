{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is not final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Stream data from Dandi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import h5py\n",
    "import remfile\n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import pynwb\n",
    "import h5py\n",
    "from fsspec.implementations.cached import CachingFileSystem\n",
    "\n",
    "\n",
    "def get_file_url(dandiset_id, filepath):\n",
    "    with DandiAPIClient() as client:\n",
    "        client.authenticate(token = '4c9c554da1def19f9b7475f941640f6fe8a0ef25')\n",
    "        asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath)\n",
    "        s3_url = asset.get_content_url(follow_redirects=1, strip_query=False)\n",
    "        return s3_url\n",
    "    \n",
    "def create_neural_assembly(psth, meta):\n",
    "    timebase = np.arange(meta[0], meta[1], meta[2])\n",
    "    timebins = np.asarray([[int(x), int(x)+int(meta[2])] for x in timebase])\n",
    "    assert len(timebase) == psth.shape[2], f\"Number of bins is not correct. Expected {len(timebase)} got {psth.shape[2]}\"\n",
    "    \n",
    "    \n",
    "    assembly = xr.DataArray(psth,\n",
    "                    coords={'repetition': ('repetition', list(range(psth.shape[1]))),\n",
    "                            'stimulus_id': ('image', list(range(psth.shape[0]))),\n",
    "                            'time_bin_id': ('time_bin', list(range(psth.shape[2]))),\n",
    "                            'time_bin_start': ('time_bin', [x[0] for x in timebins]),\n",
    "                            'time_bin_stop': ('time_bin', [x[1] for x in timebins])},\n",
    "                    dims=['image', 'repetition', 'time_bin', 'neuroid'])\n",
    "\n",
    "    assembly = assembly.stack(presentation=('image', 'repetition')).reset_index('presentation')\n",
    "\n",
    "    return assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.58.1) of dandi/dandi-cli is available. You are using 0.56.2\n"
     ]
    }
   ],
   "source": [
    "path = '/braintree/home/aliya277/000720/sub-pico'\n",
    "dandiset_id = '000720'\n",
    "file_urls = []\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    file_urls.append(get_file_url(dandiset_id, os.path.join('sub-pico', filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dandiarchive-embargo.s3.amazonaws.com/000720/blobs/c9e/bf4/c9ebf469-3643-4355-8e20-43a4e658eae7?response-content-disposition=attachment%3B%20filename%3D%22sub-pico_ses-exp-HVM-var6-2023_ecephys.nwb%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20231208%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231208T152611Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f61323e48297d07f63d814bbba17f6f1b68b1290229a28dec6e10aaade8ba4bf',\n",
       " 'https://dandiarchive-embargo.s3.amazonaws.com/000720/blobs/d3a/032/d3a03228-ec9e-4d6b-8884-0743a4bdb63f?response-content-disposition=attachment%3B%20filename%3D%22sub-pico_ses-exp-faceemovids_ecephys%2Bimage.nwb%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20231208%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231208T152611Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=62029e5c0cd4e30e036a090579952a8cdd018d1e9b6edcca6c82e41812727046']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with pynwb.NWBHDF5IO(file=file, load_namespaces=True) as io:\n",
    "        nwbfile = io.read()\n",
    "        experiment_name = nwbfile.session_id\n",
    "        for key in nwbfile.scratch.keys():\n",
    "            if key.startswith('CombinedQualityCheckedPSTHs'): \n",
    "                psth = (nwbfile.scratch[key][:])\n",
    "                # print(nwbfile.scratch['CombinedQualityCheckedPSTHs'].description[:])\n",
    "                psth_meta = [0, 300, 10]\n",
    "                assembly = create_neural_assembly(psth, psth_meta)\n",
    "        for key in nwbfile.stimulus_template.keys():\n",
    "            i = 0\n",
    "            try: (nwbfile.stimulus_template[key].external_file[:])\n",
    "            except: \n",
    "                n_stimuli = psth.shape[0]\n",
    "                for i in range(n_stimuli):\n",
    "                    print(nwbfile.stimulus_template[key].images[f'{experiment_name}_{i}.png'])\n",
    "        return assembly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a virtual filesystem based on the http protocol\n",
    "fs = fsspec.filesystem(\"http\")\n",
    "\n",
    "# create a cache to save downloaded data to disk (optional)\n",
    "fs = CachingFileSystem(\n",
    "    fs=fs,\n",
    "    cache_storage=\"nwb-cache\",  # Local folder for the cache\n",
    ")\n",
    "\n",
    "# next, open the file\n",
    "for url in file_urls:\n",
    "    with fs.open(url, \"rb\") as f:\n",
    "        with h5py.File(f) as file:\n",
    "            assembly = load_data(file)\n",
    "            print(assembly)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
